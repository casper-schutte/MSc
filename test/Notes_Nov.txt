
01/11/21:
    - Have 2 weeks to finish all the coding so that I have 6 weeks to write up.

    - To do:
        1) Fix the code, it cannot handle the positions resetting for different chromosomes.

        2) Test the algorithm/tool on real data

        Sounds easy, but I have not been able to do either.

    - I can't start testing on real data because the algorithm might change. So the priority is fixing the code.
        The problem is that when the consecutive blocks are calculated, they are not associated with the read
        name or number. In the previous iteration of the script, position (relative to the reference) was unique.
        Now, with the introduction of multiple chromosomes, the positions are no longer unique. Thus, I need to change
        the way the consecutive blocks are located or find a way to keep additional data such that the blocks are still
        identifiable.

    - One way I can overcome the problem is by using a different algorithm to return nonconsecutive blocks. I like the
        algorithm. The other way is to try to keep track of the read name while using the same algorithm. I will try
        the latter first.

02/11/21:
    - Made a lot of progress today. The script "consecutive_block_test.py" is working well using the new method.
        There are one or two kinks that might have to be worked out, but I will integrate it into my code and test
        different rearrangements. Then I will test using real data.
    - One thing I need to do is figure out how to extract the "AS" field as this will likely help me to assign borders
        more than just using the mapping quality (MAPQ). Since for FastA files there are reads that were clipped
        but still had a perfect mapping score (uniqueness).

03/11/21:
    - Will conduct some tests today to verify how the adapted algorithm works with different kinds of rearrangements.
        The results will be written up in "experiment_5.txt."
    - First round of tests were successful. Will continue tomorrow.

04/11/21:
    - Will continue with the tests of the new script. As soon as that is done I can start testing real data.

05/11/21:
    - Continued with testing the script on artificial rearrangements. See "experiment_5.txt"

06/11/21:
    - Should be finishing experiments on artificial data. Might make changes on what and how things are returned.

07/11/21:
    - Needed to make small changes. Results very good so far (see experiment_5.txt)
    - Testing multichromosoma data, see experiment_6.txt

08/11/21:
    - Finished experiment 6, see experiment_6.txt for results.
    - Ecerything is working as it should.

09/11/21:
    - Need to incorporate the new algorithm with the full script, so that we can also look at reads that did
        not map properly. These reads should correlate with the borders of rearrangements.

10/11/21:
    - Trying to fix the way that the algorithm deals with duplications. One of the duplicated pair of reads "maps" to
        the right place but the other either does not or does map but in both cases the MAPQ is 1. I would like to
        combine these reads with terrible quality scores into a single block (if they are continuous). This would
        make the output much more clear.
    - Decided it would be better if the borders and blocks were written to a .txt file instead of only being printed
        in the terminal.

13/11/21:
    - Will be trying to change the way reads are generated
    - Changing the way Bowtie2 returns reads such that coverage is increased. Multiple reads will be constructed from
        the same start position but of different lengths.
    - Did not find a way to do this in Bowtie2, but Samtools can do it:

    $ Samtools view -q (MAPQ below which reads are not returned) file_name.sam  > file_name.filtered.sam

    - After filtering out the reads with very low MAPQ (1 or 0, which were the ones that did not map or were
        duplicated), the real data proved too "noisy." My algorithm was too sensitive. Mapping single, slightly
        overlapping reads to construct continuous blocks worked very well for the artificial data. However, the real
        data proved much too noisy. Small differences in the genomes (and in the way reads happen to be mapped -
        remember that Bowtie2 uses random seeds to start looking for alignments).

    - I need to change the way reads are constructed. Multiple reads (of varying lengths) will be constructed from the
        same starting position. This way, the reads will all map where the genomes are the same. Where there is a
        breakpoint, the shorter reads should map but the longer ones map less and less well. This way, small
        differences will not be falsely returned as breakpoints. Instead, the longer (and further along) reads will
        start mapping again, confirming the small change or single badly mapped read is not a breakpoint.

    - We can make the reads overlap more, keeping the current method of construction and return, but I think that
        a more accurate method would use reads of a variable length.

    - Kept the read length at 150 bp, but made the overlap 140. Tested on the e. coli strains bl21 and k12. The
        result is a massive SAM file (188 MB !). Visually, this file is hard to go through but borders of what seem
        to be rearrangements are clear. The positional change is only 10bp, so it is very clear where subsequent reads
        do not map as well as the previous ones. It is also very clear where reads begin to map again. Small
        differences in the genome that are (likely) not rearrangement breakpoints are clearly identified as well
        since the reads quickly begin mapping properly again.

    - Pay attention to the bitwise flags (2nd column) in the SAM file as well. With this new alignment, I noticed
        some valuable information in this field that was not apparent in my small tests.

    - Need to find a "sweet spot" for read length and overlap. Consistent read positions might not matter as much
        now, so perhaps we can use variable length. We will see how further tests go.


14/11/21:
    - Will be testing the heavily overlapping reads on artificial data. I kept the files I tested the older algorithm
        on, but I would like to test on genomes that have multiple rearrangements and some other small differences,
        such that I do not fall into the same over-sensitivity.

    - After visually confirming that this method will work, I need to decide how my script will decide where borders
        are. I can look at consecutive reads and keep track of how they map. When the end of a read crosses a
        rearrangement, it will (should) have a lower MAPQ score than the previous read. It will also show some
        soft-clipping in the CIGAR string (e.g. 135M15S - 135 matching base pairs and 15 soft-clipped ones). These
        properties together should allow the script to pinpoint rearrangement breakpoints.

    - Spent most of the day driving back to stellenbosch.

15/11/21:
    - Will test the algorithm on artificial data again today. Will make multiple rearrangements and use the new method
        for creating overlapping reads. See "Experiment_7.txt" for more details.

17/11/21:
    - Needed to change the algorithm to return reads around (preceding and following) breakpoints (areas with low
        mapq that need to be investigated).

    - Have really been struggling with the code these past few days. What I want the program to do:
        Iterate over every read, start "counting" when the program encounters a read that does not map 100% correctly.
        Then, the program will keep track of how these reads map (position, MAPQ score, CIGAR string).

18/11/21:
    - Had a meeting with Prof who had a few helpful suggestions. We need to greatly increase the coverage. The reads
        will now be constructed from random starting positions until the total length of all the reads is equal to
        the coverage multiplied by the length of the original genome. This will increase the amount of times a
        nucleotide occurs in the reads. We will then look for places where mismatches start appearing from one side
        and assign a border to the last mapping read. This border will be backed up by other reads that contain it.

    - Have successfully changed the script "find_borders_test.py" such that it returns just the part of the cigar
        string that contains the number of matches

    - Have used the result above to write a function that returns the original positions of the breakpoints themselves.
        The result of the aforementioned deletion and mapping are shown below:

chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr2 	 	 9171 	 	 r2172 	 	 44 	 93M7S
Chr2 	 	 9171 	 	 r2355 	 	 42 	 81M19S
Chr2 	 	 9171 	 	 r2726 	 	 41 	 75M25S
Chr2 	 	 10444 	 	 r1477 	 	 25 	 32S68M
Chr2 	 	 10448 	 	 r1556 	 	 18 	 36S64M
Chr2 	 	 10430 	 	 r1580 	 	 42 	 18S82M
Chr2 	 	 10447 	 	 r2457 	 	 21 	 35S65M
Chr4 	 	 5602 	 	 r4268 	 	 44 	 92M8S
Chr4 	 	 5602 	 	 r3933 	 	 41 	 74M26S
Chr4 	 	 5602 	 	 r4057 	 	 25 	 72M28S
Chr4 	 	 5602 	 	 r4178 	 	 25 	 71M29S
Chr4 	 	 5602 	 	 r3650 	 	 18 	 64M36S
Chr4 	 	 5602 	 	 r4226 	 	 12 	 60M40S
Chr4 	 	 6126 	 	 r3749 	 	 2 	    48S52M
Chr4 	 	 6106 	 	 r3916 	 	 25 	 28S72M
Chr4 	 	 6101 	 	 r4323 	 	 41 	 23S77M
Chr4 	 	 6125 	 	 r4445 	 	 2 	    47S53M
Chr4 	 	 6088 	 	 r4541 	 	 44 	 10S90M
Chr4 	 	 6110 	 	 r4678 	 	 21 	 32S68M

    - Can clearly see that multiple reads confirm the positions of breakpoints. Where there is disagreement, I can
        choose to trust the breakpoint that came from the read with the highest MAPQ or perhaps take the mode.
        This is to be determined.


19/11/21:
    - Will test the new method on different rearrangements. This method is different to the previous ones in that
        continuity does not matter because the reads are generated from random starting positions. This means that
        any rearrangement should be treated the same.
        Reciprocal map of the previous experiment:

chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr2 	 	 9171 	 	 r1693 	 	 44 	 86M14S
Chr2 	 	 9171 	 	 r2113 	 	 41 	 77M23S
Chr2 	 	 9171 	 	 r1768 	 	 41 	 76M24S
Chr2 	 	 9171 	 	 r2455 	 	 36 	 69M31S
Chr2 	 	 9171 	 	 r1959 	 	 36 	 66M34S
Chr2 	 	 9171 	 	 r1664 	 	 24 	 55M45S
Chr2 	 	 9171 	 	 r2668 	 	 24 	 50M50S
Chr2 	 	 9171 	 	 r2091 	 	 22 	 43M57S
Chr2 	 	 9171 	 	 r2631 	 	 22 	 35M65S
Chr2 	 	 9171 	 	 r2396 	 	 22 	 29M71S
Chr2 	 	 9186 	 	 r1681 	 	 42 	 15S85M
Chr2 	 	 9205 	 	 r1807 	 	 36 	 34S66M
Chr2 	 	 9232 	 	 r1813 	 	 22 	 61S39M
Chr2 	 	 9194 	 	 r1948 	 	 41 	 23S77M
Chr2 	 	 9188 	 	 r2351 	 	 42 	 17S83M
Chr2 	 	 9230 	 	 r2528 	 	 22 	 59S41M
Chr2 	 	 9193 	 	 r2630 	 	 41 	 22S78M
Chr2 	 	 9183 	 	 r2763 	 	 44 	 12S88M
Chr2 	 	 9193 	 	 r2812 	 	 41 	 22S78M
Chr4 	 	 5602 	 	 r4823 	 	 42 	 79M21S
Chr4 	 	 5602 	 	 r4416 	 	 41 	 78M22S
Chr4 	 	 5602 	 	 r4318 	 	 36 	 69M31S
Chr4 	 	 5602 	 	 r4425 	 	 24 	 51M49S
Chr4 	 	 5602 	 	 r4130 	 	 22 	 34M66S
Chr4 	 	 5602 	 	 r3892 	 	 22 	 28M72S
Chr4 	 	 5643 	 	 r3777 	 	 28 	 42S58M
Chr4 	 	 5635 	 	 r3823 	 	 36 	 34S66M
Chr4 	 	 5645 	 	 r3958 	 	 24 	 44S56M
Chr4 	 	 5632 	 	 r3993 	 	 36 	 31S69M
Chr4 	 	 5646 	 	 r4453 	 	 24 	 45S55M
Chr4 	 	 5655 	 	 r4482 	 	 22 	 54S46M
Chr4 	 	 5632 	 	 r4761 	 	 36 	 31S69M

    In both cases, the first border (the border where the deletion took place) is exactly the same. The second border
    has a different position because one genome contains sequences that the other does not, due to deletions.
    Of course, what is an insertion and what is a deletion is simply a matter of perspective.

    It should not matter what kind of rearrangements are made, since we are only looking at reads that do not map.
    The exception to this is duplication which will now be tested.

    Single duplication:

chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr1 	 	 4581 	 	 r1543 	 	 25 	 30S70M
Chr1 	 	 4577 	 	 r1554 	 	 41 	 26S74M
Chr1 	 	 4594 	 	 r1599 	 	 9 	     43S57M
Chr1 	 	 4572 	 	 r2523 	 	 42 	 21S79M
Chr1 	 	 4597 	 	 r2584 	 	 2 	     46S54M
Chr1 	 	 4574 	 	 r2639 	 	 41 	 23S77M
Chr1 	 	 5321 	 	 r2441 	 	 44 	 98M2S
Chr1 	 	 5321 	 	 r2222 	 	 44 	 94M6S
Chr1 	 	 5321 	 	 r2271 	 	 44 	 93M7S
Chr1 	 	 5321 	 	 r1627 	 	 44 	 86M14S
Chr1 	 	 5321 	 	 r1960 	 	 42 	 84M16S
Chr1 	 	 5321 	 	 r1754 	 	 42 	 83M17S
Chr1 	 	 5321 	 	 r2739 	 	 9 	     54M46S
Chr2 	 	 5532 	 	 r1693 	 	 21 	 67M33S
Chr2 	 	 5561 	 	 r1859 	 	 25 	 30S70M
Chr2 	 	 5546 	 	 r2105 	 	 42 	 15S85M

    Again, we see borders clearly identified. Duplications are a little bit more tricky. This information (the
    position and MAPQ score) are enough to tell where the borders are. Perhaps not to a single base pair in ALL cases,
    but it is clear that the higher the MAPQ score, the closer the positions of the breakpoints become.

    I think an algorithm that uses the MAPQs as weights could be used to narrow down on the breakpoint.

    Reciprocal map of the previous experiment:
chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr2 	 	 5532 	 	 r1516 	 	 44 	 92M8S
Chr2 	 	 5532 	 	 r2691 	 	 41 	 74M26S
Chr2 	 	 5532 	 	 r2098 	 	 16 	 62M38S
Chr2 	 	 5532 	 	 r2083 	 	 2 	     52M48S
Chr2 	 	 5532 	 	 r2363 	 	 2 	     52M48S
Chr2 	 	 6333 	 	 r1668 	 	 21 	 32S68M
Chr2 	 	 6307 	 	 r1877 	 	 44 	 6S94M
Chr2 	 	 6341 	 	 r1984 	 	 12 	 40S60M
Chr2 	 	 6319 	 	 r2009 	 	 42 	 18S82M
Chr2 	 	 6312 	 	 r2018 	 	 44 	 11S89M
Chr2 	 	 6327 	 	 r2578 	 	 41 	 26S74M
Chr2 	 	 6315 	 	 r2602 	 	 44 	 14S86M
Chr2 	 	 6345 	 	 r2745 	 	 9 	     44S56M

    In this experiment, the only reads that were returned were the borders of the duplication. In the sorted SAM file
    there are reads in between these that all have a mapping quality of 1. It might be useful look at these reads
    as well because they would indicate the position the duplication originated from. Nevertheless, the script
    identified all of the borders, and only the borders. Real data is much more noisy. This means that I need a
    function that looks at how many times a potential border is contained in a read. A foreseeable problem is that
    the reads do not report the exact same position for the border. So, how to filter out the noise reads and keep the
    actual ones is my next problem.

    Idea: Go through the reads, give each returned potential breakpoint a weight (probably based on MAPQ). The lower
    the MAPQ, the more allowance on either side.

    Read length and coverage need to be optimised. This could be left up to the user but it would be good to have a
    default that would work in common use.


20/11/21:
    - Thinking about how to group the borders. Given that the read length is 100, we definitely do not want to use
        a read that maps the border more than 100 positions away.

23/11/21:
    - There are two strategies I am considering
        1) Extend the border area around the breakpoint proportionately to how LOW the MAPQ is. This follows from the
            observation that the lower the MAPQ, the further the border is assigned from the actual border. In other
            words, if a border is assigned at 1105, with MAPQ of 44, the border will be extended by 1 bp on both sides
            (or one side, look at the data). if another border is assigned at 1120, with a low MAPQ (10), we can
            extend that 1120 on both sides by some number of base pairs.
            We then look at the borders with the highest confidence and "back them up" by finding this position
            in the extended borders of the borders with lower confidence.

        2) The other strategy is to create an array of all the borders and then use Numpy.average(). This function
            returns the average of the values in an array. When a second array is used in the argument, it is used
            as a weight for each value. This would decrease the affect that borders with low confidence have
            on the outcome.


        A combination of these two strategies might work. I would get the borders that map in roughly the same area.
        Take the border with the highest confidence as a starting point, then check if other borders fall in the same
        region (allowing more extension for borders with bad MAPQ). I could then collect these and use these to get
        the average (weighted). This will only really work if the "bad" borders are mapped to both sides. If they
        are disproportionately to one side then this will pull the average away from the actual border.

24/11/21:
    - I have created a function in "find_borders_test.py" that separates the most confident breakpoints from
        each other by looking at the positions. There is an allowance variable that allows the positions to differ
        on either side by some integer. The high confidence borders are lists within lists. Borders that map very
        well and are within (allowance) base pairs are in the same list.

        I need to write another function or extend the current one in order to add the less confident breakpoints
        to the lists.

    - Done. Extended the function such that the borders that have lower mapq score are appended to the list containing
        the higher mapq border, if they are within some distance (allowance variable). We can use the borders within
        reads that had a MAPQ lower than the maximum to add confidence

26/11/21:
    - Result of algorithm:

chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr2 	 	 5532 	 	 r1516 	 	 44 	 92M8S
Chr2 	 	 5532 	 	 r2691 	 	 41 	 74M26S
Chr2 	 	 5532 	 	 r2098 	 	 16 	 62M38S
Chr2 	 	 5532 	 	 r2083 	 	 2 	     52M48S
Chr2 	 	 5532 	 	 r2363 	 	 2 	     52M48S

Chr2 	 	 6307 	 	 r1877 	 	 44 	 6S94M
Chr2 	 	 6312 	 	 r2018 	 	 44 	 11S89M
Chr2 	 	 6315 	 	 r2602 	 	 44 	 14S86M
Chr2 	 	 6333 	 	 r1668 	 	 21 	 32S68M
Chr2 	 	 6341 	 	 r1984 	 	 12 	 40S60M
Chr2 	 	 6319 	 	 r2009 	 	 42 	 18S82M
Chr2 	 	 6327 	 	 r2578 	 	 41 	 26S74M
Chr2 	 	 6345 	 	 r2745 	 	 9 	     44S56M

The borders with the highest confidence are extracted from the rest and then grouped by position. Then, the remaining
borders are compared with the high confidence borders. If they are within an allowable distance from a high confidence
border, they are added to the list.

    - It is time to test on a different file with rearrangements in different places.
        The multichromosomal test genome "lv_mc.fa" will be rearranged to include a deletion and a translocation.
        The new file will be named "exp7_3.fa" and reads will be constructed from it and mapped reciprocally to the
        original lv_mc.fa file. I will keep track of the positions of the breakpoints to evaluate the accuracy.

    - (I still need to think of a way to report the total confidence.)

    - Rearrangements: Deletion of 140 bp at position 1330 (up to position 1470) on chromosome 1.

    - Translocation (150bp) from position 700 on chromosome 3 to end of chromosome 4

Mapping:
Rearranged onto original:
chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr1 	 	 1333 	 	 r356 	 	 44 	 99M1S
Chr1 	 	 1333 	 	 r1038 	 	 44 	 93M7S
Chr1 	 	 1333 	 	 r381 	 	 21 	 67M33S
Chr1 	 	 1333 	 	 r726 	 	 21 	 67M33S
Chr1 	 	 1333 	 	 r32 	 	 18 	 64M36S
Chr1 	 	 1333 	 	 r302 	 	 16 	 62M38S
Chr1 	 	 1333 	 	 r767 	 	 16 	 62M38S

Chr1 	 	 1481 	 	 r627 	 	 44 	 10S90M
Chr1 	 	 1489 	 	 r571 	 	 42 	 18S82M
Chr1 	 	 1504 	 	 r662 	 	 21 	 33S67M
Chr1 	 	 1519 	 	 r1121 	 	 2 	     48S52M
Chr1 	 	 1501 	 	 r1126 	 	 25 	 30S70M
Chr1 	 	 1511 	 	 r1216 	 	 12 	 40S60M

Chr3 	 	 709 	 	 r4323 	 	 44 	 8S92M
Chr3 	 	 701 	 	 r3460 	 	 42 	 83M17S
Chr3 	 	 701 	 	 r3312 	 	 42 	 82M18S
Chr3 	 	 701 	 	 r2979 	 	 41 	 73M27S
Chr3 	 	 701 	 	 r3446 	 	 21 	 67M33S
Chr3 	 	 701 	 	 r3591 	 	 9 	     55M45S
Chr3 	 	 701 	 	 r3463 	 	 9 	     54M46S
Chr3 	 	 722 	 	 r4245 	 	 42 	 21S79M
Chr3 	 	 746 	 	 r4362 	 	 9 	     45S55M
Chr3 	 	 717 	 	 r4755 	 	 42 	 16S84M

Chr3 	 	 858 	 	 r3587 	 	 44 	 7S93M
Chr3 	 	 883 	 	 r3160 	 	 25 	 32S68M
Chr3 	 	 875 	 	 r3213 	 	 41 	 24S76M
Chr3 	 	 892 	 	 r3471 	 	 12 	 41S59M

Chr4 	 	 10773 	 	 r4340 	 	 44 	 88M12S


Original mapped onto rearranged:
chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr1 	 	 1333 	 	 r701 	 	 44 	 99M1S
Chr1 	 	 1333 	 	 r1293 	 	 44 	 93M7S
Chr1 	 	 1342 	 	 r33 	 	 44 	 11S89M
Chr1 	 	 1333 	 	 r558 	 	 36 	 69M31S
Chr1 	 	 1333 	 	 r745 	 	 36 	 69M31S
Chr1 	 	 1333 	 	 r842 	 	 22 	 49M51S
Chr1 	 	 1333 	 	 r985 	 	 22 	 34M66S
Chr1 	 	 1333 	 	 r1156 	 	 22 	 28M72S
Chr1 	 	 1333 	 	 r1301 	 	 22 	 28M72S
Chr1 	 	 1366 	 	 r337 	 	 36 	 35S65M
Chr1 	 	 1356 	 	 r1040 	 	 41 	 25S75M

Chr3 	 	 701 	 	 r3577 	 	 44 	 99M1S
Chr3 	 	 701 	 	 r3608 	 	 44 	 99M1S
Chr3 	 	 701 	 	 r3274 	 	 44 	 95M5S
Chr3 	 	 701 	 	 r2973 	 	 44 	 94M6S
Chr3 	 	 710 	 	 r3747 	 	 44 	 9S91M
Chr3 	 	 701 	 	 r3477 	 	 25 	 71M29S
Chr3 	 	 701 	 	 r2978 	 	 25 	 68M32S
Chr3 	 	 701 	 	 r3502 	 	 21 	 67M33S
Chr3 	 	 701 	 	 r3152 	 	 9 	     57M43S
Chr3 	 	 701 	 	 r3520 	 	 2 	     53M47S
Chr3 	 	 744 	 	 r3191 	 	 9 	     43S57M
Chr3 	 	 719 	 	 r3213 	 	 42 	 18S82M
Chr3 	 	 728 	 	 r3215 	 	 41 	 27S73M

Chr4 	 	 10777 	 	 r3360 	 	 44 	 4S96M
Chr4 	 	 10786 	 	 r3737 	 	 44 	 13S87M
Chr4 	 	 10822 	 	 r3006 	 	 2 	     49S51M
Chr4 	 	 10817 	 	 r3062 	 	 9 	     44S56M
Chr4 	 	 10800 	 	 r3536 	 	 41 	 27S73M

Chr4 	 	 10923 	 	 r2989 	 	 44 	 98M2S
Chr4 	 	 10923 	 	 r3204 	 	 41 	 76M24S
Chr4 	 	 10923 	 	 r3052 	 	 37 	 72M28S
Chr4 	 	 10923 	 	 r3424 	 	 9 	     55M45S
Chr4 	 	 10923 	 	 r3111 	 	 2 	     51M49S

Chr1 	 	 1399 	 	 r485 	 	 22 	 68S32M

Chr1 	 	 1389 	 	 r802 	 	 22 	 58S42M

Chr1 	 	 1390 	 	 r1182 	 	 22 	 59S41M


Discussion:
    - I noticed something VERY IMPORTANT. I have overlooked an important detail. I noticed that for the reads that
        start mapping and then stop (have M - for match before S - for soft-clipped) the correct positions are
        returned for the breakpoints. In the other case where reads start with soft-clipped bases the positions are
        off. This is because when a base is marked as soft-clipped, the position is NOT changed. This means that
        I should not be adjusting the position of the reads in this case. I will change the script and check the
        results.

    - Changed script to NO LONGER adjust the position of the breakpoints that start out as soft-clipped.
        Results:
chromosome 	 position 	 read name 	 MAPQ 	 CIGAR string
Chr1 	 	 1333 	 	 r701 	 	 44 	 99M1S
Chr1 	 	 1333 	 	 r1293 	 	 44 	 93M7S
Chr1 	 	 1331 	 	 r33 	 	 44 	 11S89M
Chr1 	 	 1333 	 	 r558 	 	 36 	 69M31S
Chr1 	 	 1333 	 	 r745 	 	 36 	 69M31S
Chr1 	 	 1333 	 	 r842 	 	 22 	 49M51S
Chr1 	 	 1333 	 	 r985 	 	 22 	 34M66S
Chr1 	 	 1333 	 	 r1156 	 	 22 	 28M72S
Chr1 	 	 1333 	 	 r1301 	 	 22 	 28M72S
Chr1 	 	 1331 	 	 r337 	 	 36 	 35S65M
Chr1 	 	 1331 	 	 r485 	 	 22 	 68S32M
Chr1 	 	 1331 	 	 r802 	 	 22 	 58S42M
Chr1 	 	 1331 	 	 r1040 	 	 41 	 25S75M
Chr1 	 	 1331 	 	 r1182 	 	 22 	 59S41M

Chr3 	 	 701 	 	 r3577 	 	 44 	 99M1S
Chr3 	 	 701 	 	 r3608 	 	 44 	 99M1S
Chr3 	 	 701 	 	 r3274 	 	 44 	 95M5S
Chr3 	 	 701 	 	 r2973 	 	 44 	 94M6S
Chr3 	 	 701 	 	 r3747 	 	 44 	 9S91M
Chr3 	 	 701 	 	 r3477 	 	 25 	 71M29S
Chr3 	 	 701 	 	 r2978 	 	 25 	 68M32S
Chr3 	 	 701 	 	 r3502 	 	 21 	 67M33S
Chr3 	 	 701 	 	 r3152 	 	 9 	     57M43S
Chr3 	 	 701 	 	 r3520 	 	 2 	     53M47S
Chr3 	 	 701 	 	 r3191 	 	 9 	     43S57M
Chr3 	 	 701 	 	 r3213 	 	 42 	 18S82M
Chr3 	 	 701 	 	 r3215 	 	 41 	 27S73M

Chr4 	 	 10773 	 	 r3360 	 	 44 	 4S96M
Chr4 	 	 10773 	 	 r3737 	 	 44 	 13S87M
Chr4 	 	 10773 	 	 r3006 	 	 2 	     49S51M
Chr4 	 	 10773 	 	 r3062 	 	 9 	     44S56M
Chr4 	 	 10773 	 	 r3536 	 	 41 	 27S73M

Chr4 	 	 10923 	 	 r2989 	 	 44 	 98M2S
Chr4 	 	 10923 	 	 r3204 	 	 41 	 76M24S
Chr4 	 	 10923 	 	 r3052 	 	 37 	 72M28S
Chr4 	 	 10923 	 	 r3424 	 	 9 	     55M45S
Chr4 	 	 10923 	 	 r3111 	 	 2 	     51M49S

    Discussion: Holy shit... it works.
    I have verified that the positions returned are NOT simply a bug or error that returns the same value. These
    positions are derived from the SAM file. These results are fantastic. There are so many reads that support the
    reads that map with high confidence.